<h2 align="center">
:tophat: Topic Modeling with Style :tophat:
  
</h2>

## Abstract 
Recent breakthroughs with Large Language Models (LLMs) have prompted concerns about threats
including fake news, email phishing, and dataset contamination (Weber-Wulff et al., 2023; Heiding
et al., 2023). Unfortunately, detecting AI generated text remains a challenge. We explore applying
topic modeling to this task, and modeling stylistic properties of texts written by human and
AI authors more broadly. Current probabilistic topic models are typically limited to modeling
collections of documents by their individual terms to form topics, while the aforementioned notions
of style generally include patterns beyond individual terms (e.g., syntax, punctuation, or multi-word
phrases). To better model textual style, we introduce ProdSLDA, an extension of ProdLDA that
jointly models styles alongside topics. We evaluate the ProdSLDAâ€™s capabilities in encoding stylistic
features as well as evaluate whether our approach can provide interpretable style embeddings that
enable identifying text generated by LLMs and performing authorship identification.

## Data
- Our filtered Enron Email dataset is in ``data/enron``.
- Our data generation scripts + ChatGPT inferences, are in `data_generation`

## Scripts
- ``explore_latents.ipynb``, contains our code for analyzing model latents and training classifiers.
- ``hparam_tuning.ipynb``, contains our hyperameter tuning code
- ``model_fit_evaluation.ipynb``, contains our model evaluation scripts
- ``plate_diagrams.ipynb``, contains our plate diagrams
- ``single_fit.ipynb``, contains our logic for fitting our independent baseline, that **does not** jointly model style and document terms.

## ProdSLDA
- ``prod_slda`` contains our ProdSLDA model, which is implemented in Pyro, our topic evaluation scripts, and our data utilities.

