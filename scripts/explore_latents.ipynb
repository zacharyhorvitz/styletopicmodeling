{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import torch\n",
    "import json\n",
    "import pickle\n",
    "import os \n",
    "from prodslda_cls import ProdSLDA\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "MODEL_PATH = '/burg/nlp/users/zfh2000/style_results/pos_bigrams/2023-12-14_17_54_45/model_epoch5_20914.218841552734.pt'\n",
    "DATA_DIR_PATH = '/burg/nlp/users/zfh2000/style_results/pos_bigrams/maxdf0.5_mindf5_DATA'\n",
    "\n",
    "with open(os.path.join(DATA_DIR_PATH, 'bows.pickle'), 'rb') as in_file:\n",
    "    bows = pickle.load(in_file)\n",
    "        \n",
    "with open(os.path.join(DATA_DIR_PATH, 'meta_vectorized.pickle'), 'rb') as in_file:\n",
    "    meta_vectorized = pickle.load(in_file)    \n",
    "\n",
    "with open(os.path.join(DATA_DIR_PATH, \"raw_text.json\"), 'r') as in_file:\n",
    "    raw_text = json.load(in_file)    \n",
    "\n",
    "with open(os.path.join(DATA_DIR_PATH, \"authors_json.json\"), 'r') as in_file:\n",
    "    authors_json = json.load(in_file)    \n",
    "\n",
    "with open(os.path.join(DATA_DIR_PATH, \"meta_feature_to_names.json\"), 'r') as in_file:\n",
    "    meta_feature_to_names = json.load(in_file)\n",
    "\n",
    "with open(os.path.join(DATA_DIR_PATH, \"vectorizer.pickle\"), 'rb') as in_file:\n",
    "    vectorizer = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProdSLDA(\n",
       "  (encoder): GeneralEncoder(\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (fc1s): ModuleDict(\n",
       "      (doc): Linear(in_features=9267, out_features=64, bias=True)\n",
       "    )\n",
       "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (fcmu): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (fclv): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (bnmu): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (bnlv): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (beta): Linear(in_features=10, out_features=9267, bias=False)\n",
       "    (bn): BatchNorm1d(9267, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (style_encoder): GeneralEncoder(\n",
       "    (drop): Dropout(p=0, inplace=False)\n",
       "    (fc1s): ModuleDict(\n",
       "      (pos_bigrams): Linear(in_features=324, out_features=64, bias=True)\n",
       "    )\n",
       "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (fcmu): Linear(in_features=64, out_features=5, bias=True)\n",
       "    (fclv): Linear(in_features=64, out_features=5, bias=True)\n",
       "    (bnmu): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "    (bnlv): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "  )\n",
       "  (style_decoder): ModuleDict(\n",
       "    (pos_bigrams): Decoder(\n",
       "      (beta): Linear(in_features=5, out_features=324, bias=False)\n",
       "      (bn): BatchNorm1d(324, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      (drop): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "\n",
    "prodsdla = torch.load(MODEL_PATH)\n",
    "prodsdla.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_beta_document(model, vectorizer, top_k=20):\n",
    "    betas_document = model.beta_document()\n",
    "    features_to_betas = {}\n",
    "    idx_to_name = {v:k for k,v in vectorizer.vocabulary_.items()}\n",
    "    for feature, logits in betas_document.items():\n",
    "        features_to_betas[feature] = []\n",
    "        num_features = logits.shape[0]\n",
    "        top_results = torch.topk(logits, top_k, dim=-1)\n",
    "        \n",
    "        ids = top_results.indices.cpu().numpy()\n",
    "        values = top_results.values.cpu().numpy()\n",
    "        \n",
    "        for i in tqdm(range(num_features)):\n",
    "            features_to_betas[feature].append({'values':values[i], 'top':[idx_to_name[idx] for idx in ids[i]]})\n",
    "                \n",
    "    return features_to_betas\n",
    "\n",
    "def top_beta_meta(model, meta_feature_to_names, top_k=20):\n",
    "    betas_metas = model.beta_meta()\n",
    "    features_to_betas = {}\n",
    "    for feature, logits in betas_metas.items():\n",
    "        idx_to_name = {i:k for i,k in enumerate(meta_feature_to_names[feature])}\n",
    "        features_to_betas[feature] = []\n",
    "        num_features = logits.shape[0]\n",
    "        top_results = torch.topk(logits, top_k, dim=-1)\n",
    "        ids = top_results.indices.cpu().numpy()\n",
    "        values = top_results.values.cpu().numpy()\n",
    "        for i in tqdm(range(num_features)):\n",
    "            features_to_betas[feature].append({'values':values[i], 'top':[idx_to_name[idx] for idx in ids[i]]})\n",
    "        \n",
    "    return features_to_betas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 3308.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 36663.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Term Info\n",
      "\tbeta_topic (10):\n",
      "\t\t beta_topic (0):\n",
      "['fine', 'hope', 'sally', '28', '09', 'stuff', '08', 'hourahead', 'night', 'attached', 'jim', 'tickets', 'energy', 'making', 'presentation', 'kitchen', 'manual', '713', 'linda', 'original']\n",
      "\n",
      "\t\t beta_topic (1):\n",
      "['silva', 'geae', '962', '7566', 'eb3892', 'manis', 'x33278', '1575', 'freyre', 'bambos', 'ccampbell', 'giuseppe', 'vande', 'kupiecki', '4727', 'noncore', 'kayne', 'mckinsey', 'nassos', 'centilli']\n",
      "\n",
      "\t\t beta_topic (2):\n",
      "['fax', '713', 'john', 'market', 'bcc', 'help', 'yes', 'needs', 'hey', 'request', 'credit', 'questions', 'deals', 'address', 'updates', 'message', 'email', '646', 'management', 'www']\n",
      "\n",
      "\t\t beta_topic (3):\n",
      "['print', 'attachment', 'enron', 'report', 'asked', '07', 'format', 'sppc', 'wrong', 'job', 'waiting', 'kate', 'information', 'language', 'retain', 'time', 'sorry', 'attached', '00', 'basis']\n",
      "\n",
      "\t\t beta_topic (4):\n",
      "['fyi', 'need', 'just', 'meeting', 'sent', 'thanks', 'ferc', '2000', 'mark', 'revised', 'going', 'draft', 'help', 'update', '07', 'report', 'file', 'description', 'tuesday', 'order']\n",
      "\n",
      "\t\t beta_topic (5):\n",
      "['know', '12', 'deal', 'fyi', 'enron', 'did', 'wednesday', 'day', 'weekend', 'master', 'pdt', 'soon', 'john', 'bob', 'chris', 'yes', 'com', 'cc', '14', '05']\n",
      "\n",
      "\t\t beta_topic (6):\n",
      "['5426', 'eb3892', 'fairisaac', 'eb3816', 'nassos', '6794', 'retain', 'gco', 'freshfields', '3858', 'mday', '50m', 'centilli', 'harvey', '8600', 'livingston', 'sarimah', '4727', '0518', 'x33278']\n",
      "\n",
      "\t\t beta_topic (7):\n",
      "['kirstee', 'barkovich', 'lucas', 'redsky', 'howzabout', 'vande', 'mhc', 'psellers', 'master', '2001', 'eb3892', 'portable', 'maxwell', 'centilli', 'nmann', 'nassos', 'feeds', 'start', '1890', 'rakesh']\n",
      "\n",
      "\t\t beta_topic (8):\n",
      "['6794', 'nfb', 'bambos', 'napa', 'giuseppe', 'congratz', 'kayne', '4727', 'vande', 'ws', 'kupiecki', 'eb1336', 'montjoy', 'x37972', 'distance', 'ccampbell', 'kirstee', 'noncore', 'trv', 'silva']\n",
      "\n",
      "\t\t beta_topic (9):\n",
      "['week', 'afternoon', 'let', 'night', 'feedback', '2002', 'wednesday', 'send', '07', 'mon', 'john', 'feb', 'tomorrow', 'print', 'dynegy', 'kate', 'today', 'question', 'questions', '05']\n",
      "\n",
      "Meta Var Info\n",
      "\tpos_bigrams (5):\n",
      "\t\t pos_bigrams (0):\n",
      "['pos_bigrams:NOUN NOUN', 'pos_bigrams:ADP DET', 'pos_bigrams:PUNCT NUM', 'pos_bigrams:PROPN NUM', 'pos_bigrams:ADP PUNCT', 'pos_bigrams:PROPN PART', 'pos_bigrams:VERB DET', 'pos_bigrams:AUX VERB', 'pos_bigrams:PART NOUN', 'pos_bigrams:PRON VERB', 'pos_bigrams:PUNCT PUNCT', 'pos_bigrams:NOUN ADP', 'pos_bigrams:ADP CCONJ', 'pos_bigrams:PROPN PRON', 'pos_bigrams:NOUN ADV', 'pos_bigrams:NOUN CCONJ', 'pos_bigrams:PUNCT AUX', 'pos_bigrams:INTJ VERB', 'pos_bigrams:VERB PRON', 'pos_bigrams:ADJ NUM']\n",
      "\n",
      "\t\t pos_bigrams (1):\n",
      "['pos_bigrams:PART INTJ', 'pos_bigrams:AUX NUM', 'pos_bigrams:INTJ SPACE', 'pos_bigrams:X PROPN', 'pos_bigrams:DET SYM', 'pos_bigrams:DET PUNCT', 'pos_bigrams:SPACE NOUN', 'pos_bigrams:SPACE ADP', 'pos_bigrams:INTJ ADJ', 'pos_bigrams:NOUN DET', 'pos_bigrams:SYM ADV', 'pos_bigrams:SYM VERB', 'pos_bigrams:SPACE SPACE', 'pos_bigrams:ADV PRON', 'pos_bigrams:VERB SPACE', 'pos_bigrams:DET X', 'pos_bigrams:PROPN DET', 'pos_bigrams:ADJ SYM', 'pos_bigrams:SPACE X', 'pos_bigrams:DET CCONJ']\n",
      "\n",
      "\t\t pos_bigrams (2):\n",
      "['pos_bigrams:DET SYM', 'pos_bigrams:PART INTJ', 'pos_bigrams:INTJ PRON', 'pos_bigrams:SYM ADV', 'pos_bigrams:DET PRON', 'pos_bigrams:AUX SCONJ', 'pos_bigrams:DET PUNCT', 'pos_bigrams:AUX NUM', 'pos_bigrams:VERB SPACE', 'pos_bigrams:SPACE SPACE', 'pos_bigrams:SPACE ADP', 'pos_bigrams:INTJ ADJ', 'pos_bigrams:SYM VERB', 'pos_bigrams:ADP SPACE', 'pos_bigrams:PUNCT INTJ', 'pos_bigrams:PROPN DET', 'pos_bigrams:INTJ INTJ', 'pos_bigrams:ADP SCONJ', 'pos_bigrams:DET X', 'pos_bigrams:NUM SPACE']\n",
      "\n",
      "\t\t pos_bigrams (3):\n",
      "['pos_bigrams:PROPN PART', 'pos_bigrams:ADJ SYM', 'pos_bigrams:PRON DET', 'pos_bigrams:NOUN PROPN', 'pos_bigrams:INTJ SYM', 'pos_bigrams:PUNCT AUX', 'pos_bigrams:ADP INTJ', 'pos_bigrams:PRON VERB', 'pos_bigrams:ADP CCONJ', 'pos_bigrams:PUNCT PART', 'pos_bigrams:ADV AUX', 'pos_bigrams:ADJ NUM', 'pos_bigrams:PUNCT ADP', 'pos_bigrams:ADP VERB', 'pos_bigrams:NOUN VERB', 'pos_bigrams:AUX ADP', 'pos_bigrams:PROPN AUX', 'pos_bigrams:ADJ CCONJ', 'pos_bigrams:PUNCT ADJ', 'pos_bigrams:PRON SYM']\n",
      "\n",
      "\t\t pos_bigrams (4):\n",
      "['pos_bigrams:ADJ SYM', 'pos_bigrams:ADP INTJ', 'pos_bigrams:PRON SYM', 'pos_bigrams:INTJ SYM', 'pos_bigrams:PROPN PART', 'pos_bigrams:ADV NUM', 'pos_bigrams:INTJ ADJ', 'pos_bigrams:PUNCT PART', 'pos_bigrams:PRON DET', 'pos_bigrams:DET CCONJ', 'pos_bigrams:PUNCT AUX', 'pos_bigrams:NOUN PROPN', 'pos_bigrams:PROPN ADP', 'pos_bigrams:PROPN DET', 'pos_bigrams:SPACE SPACE', 'pos_bigrams:PROPN AUX', 'pos_bigrams:SPACE INTJ', 'pos_bigrams:DET X', 'pos_bigrams:AUX ADP', 'pos_bigrams:SPACE ADP']\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_words_per_latent = top_beta_document(prodsdla, vectorizer,  top_k=20)\n",
    "top_meta_per_latent = top_beta_meta(prodsdla, meta_feature_to_names, top_k=20)\n",
    "\n",
    "print('Document Term Info')\n",
    "for latent, top in top_words_per_latent.items():\n",
    "    print(f'\\t{latent} ({len(top)}):')\n",
    "    for i, results in enumerate(top):\n",
    "        print(f'\\t\\t {latent} ({i}):\\n{results[\"top\"]}')\n",
    "        print()\n",
    "\n",
    "print('Meta Var Info')\n",
    "for latent, top in top_meta_per_latent.items():\n",
    "\n",
    "    print(f'\\t{latent} ({len(top)}):')\n",
    "    for i, results in enumerate(top):\n",
    "        print(f'\\t\\t {latent} ({i}):\\n{results[\"top\"]}')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66668, 9267)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bows['training'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                          | 0/66668 [00:00<?, ?it/s]/tmp/ipykernel_3694250/3563969272.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  b = torch.tensor(torch.tensor(bows['training'][i]).unsqueeze(0).float().to(DEVICE))\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 66668/66668 [03:37<00:00, 306.93it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "DEVICE='cuda'\n",
    "meta_vectorized['training'] = {k:v.toarray() for k,v in meta_vectorized['training'].items()}\n",
    "\n",
    "author_to_result = {}\n",
    "\n",
    "bows['training'] = bows['training'].toarray()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i in tqdm(range(len(raw_text['training']))):\n",
    "        text = raw_text['training'][i]\n",
    "        author = authors_json['training'][i]\n",
    "        b = torch.tensor(torch.tensor(bows['training'][i]).unsqueeze(0).float().to(DEVICE))\n",
    "        m = {k:torch.tensor(v[i]).unsqueeze(0).float().to(DEVICE) for k,v in meta_vectorized['training'].items()}\n",
    "        # print(b)\n",
    "        # print(m)\n",
    "\n",
    "        theta, kappa =  prodsdla.guide(b, m)\n",
    "\n",
    "        theta = F.softmax(theta,-1).detach().cpu()\n",
    "        kappa = F.softmax(kappa,-1).detach().cpu()\n",
    "        if author not in author_to_result:\n",
    "            author_to_result[author] = []\n",
    "            \n",
    "        author_to_result[author].append((text, theta, kappa))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_to_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_list = sorted(author_to_result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = len(author_to_result[author_list[0]][0][1][0])\n",
    "num_styles = len(author_to_result[author_list[0]][0][2][0])\n",
    "\n",
    "topics_to_top_examples = {i:[] for i in range(num_topics)}\n",
    "style_to_top_examples = {i:[] for i in range(num_styles)}\n",
    "\n",
    "for a in tqdm(author_to_result):\n",
    "    for text, theta, kappa in author_to_result[a]:\n",
    "        for i, x in enumerate(theta[0]):\n",
    "            topics_to_top_examples[i].append((x, a,text))\n",
    "        for i, x in enumerate(kappa[0]):\n",
    "            style_to_top_examples[i].append((x, a,text))\n",
    "            \n",
    "            \n",
    "topics_to_top_examples = {i: sorted(v) for i,v in topics_to_top_examples.items()}        \n",
    "style_to_top_examples = {i: sorted(v) for i,v in style_to_top_examples.items()}  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in topics_to_top_examples.items():\n",
    "    print(\"TOPIC\",i)\n",
    "    print(v[-5:])\n",
    "    print()\n",
    "\n",
    "for i, v in style_to_top_examples.items():\n",
    "    print(\"STYLE\",i)\n",
    "    print(v[-5:])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_projection(x):\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(x)\n",
    "    return pca.transform(x)\n",
    "\n",
    "def plot_projection(x, y, authors):\n",
    "    color = ['red', 'blue', 'green', 'purple', 'orange', 'yellow', 'black', 'pink', 'brown', 'gray']\n",
    "    \n",
    "    # is_gpt = [a.startswith('gpt3.5_') for a in authors]\n",
    "    # authors_norm = [a.replace('gpt3.5_','') for a in authors]\n",
    "\n",
    "    nongpt_x = []\n",
    "    nongpt_y = []\n",
    "    human_labels = []\n",
    "\n",
    "    gpt_x = []\n",
    "    gpt_y = []\n",
    "    gpt_labels = []\n",
    "\n",
    "    for i, a in enumerate(authors):\n",
    "        if a.startswith('gpt3.5_'):\n",
    "            gpt_x.append(x[i])\n",
    "            gpt_y.append(y[i])\n",
    "            gpt_labels.append(a)\n",
    "        else:\n",
    "            nongpt_x.append(x[i])\n",
    "            nongpt_y.append(y[i])\n",
    "            human_labels.append(a)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.scatter(nongpt_x, nongpt_y, color='red', label='human')\n",
    "    plt.scatter(gpt_x, gpt_y, color='blue', label='synthetic')\n",
    "\n",
    "    # for i, label in enumerate(human_labels):\n",
    "        # plt.annotate(label, (nongpt_x[i], nongpt_y[i]))\n",
    "\n",
    "    # TODO: match specific authors to specific colors, use different shapes for gpt vs human\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = []\n",
    "kappas = []\n",
    "a_labels = []\n",
    "texts = []\n",
    "\n",
    "for a in tqdm(sorted(author_to_result.keys())):\n",
    "    for text, theta, kappa in author_to_result[a]:\n",
    "        kappas.append(kappa[0])\n",
    "        thetas.append(theta[0])\n",
    "        a_labels.append(a)\n",
    "        texts.append(text)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_proj = compute_projection(np.stack(kappas))\n",
    "plot_projection(kappa_proj[:,0], kappa_proj[:,1], a_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_proj = compute_projection(np.stack(thetas))\n",
    "plot_projection(theta_proj[:,0], theta_proj[:,1], a_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def plot_projection_comparison(x, y, authors):\n",
    "    color = ['pink', 'blue','black'] #['red', 'blue', 'green', 'purple', 'orange', 'yellow', 'black', 'pink', 'brown', 'gray']\n",
    "\n",
    "\n",
    "    \n",
    "    is_gpt = [a for a in authors if a.startswith('gpt3.5_')]\n",
    "    authors_paired = [a for a in authors if 'gpt3.5_'+a in is_gpt]\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    for c, chosen_a in enumerate(sorted(set(authors_paired))[:len(color)]):\n",
    "        nongpt_x = []\n",
    "        nongpt_y = []\n",
    "    \n",
    "        gpt_x = []\n",
    "        gpt_y = []\n",
    "\n",
    "        for i, a in enumerate(authors):\n",
    "            if chosen_a not in a: continue\n",
    "            if a.startswith('gpt3.5_'):\n",
    "                gpt_x.append(x[i])\n",
    "                gpt_y.append(y[i])\n",
    "            else:\n",
    "                nongpt_x.append(x[i])\n",
    "                nongpt_y.append(y[i])\n",
    "\n",
    "        \n",
    "\n",
    "                \n",
    "        \n",
    "   \n",
    "        plt.scatter(nongpt_x, nongpt_y, color=color[c], label='human', marker='.')\n",
    "        plt.scatter(gpt_x, gpt_y, color=color[c], label='synthetic', marker='x')\n",
    "\n",
    "        for i in range(len(gpt_x)):\n",
    "            distances = [(math.dist([gpt_x[i], gpt_y[i]], [nongpt_x[j], nongpt_y[j]]), ([nongpt_x[j], nongpt_y[j]])) for j in range(len(nongpt_x))]\n",
    "            distances = sorted(distances)\n",
    "            plt.plot([gpt_x[i], distances[0][1][0]], [gpt_y[i], distances[0][1][1]], color=color[c], linestyle='--', linewidth=0.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection_comparison(kappa_proj[:,0], kappa_proj[:,1], a_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_projection_comparison(theta_proj[:,0], theta_proj[:,1], a_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
